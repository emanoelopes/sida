from pathlib import Path
import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import pickle
import time
try:
    from .carregar_dados import carregar_uci_dados, carregar_oulad_dados
except ImportError:
    # Fallback para quando executado diretamente
    from carregar_dados import carregar_uci_dados, carregar_oulad_dados

def leitura_oulad_data():
    """Fun√ß√£o para leitura dos dados OULAD - mantida para compatibilidade"""
    datasets_path = Path(__file__).parent.parents[1] / 'datasets' / 'oulad_data'
    return datasets_path

@st.cache_data(ttl=3600)  # Cache por 1 hora
def carregar_dados_uci_cached():
    """Carrega dados UCI com cache"""
    return carregar_uci_dados()

@st.cache_data(ttl=3600)  # Cache por 1 hora
def carregar_dados_oulad_cached():
    """Carrega dados OULAD com cache"""
    return carregar_oulad_dados()

def carregar_dados_dashboard():
    """Carrega os dados processados para o dashboard com cache"""
    try:
        # Carregar dados UCI com cache
        df_uci = carregar_dados_uci_cached()
        st.session_state['df_uci'] = df_uci
    except Exception as e:
        st.warning(f"Erro ao carregar dados UCI: {e}")
        df_uci = pd.DataFrame()
        st.session_state['df_uci'] = df_uci
    
    try:
        # Carregar dados OULAD com cache
        df_oulad = carregar_dados_oulad_cached()
        st.session_state['df_oulad'] = df_oulad
    except Exception as e:
        st.warning(f"Erro ao carregar dados OULAD: {e}")
        df_oulad = pd.DataFrame()
        st.session_state['df_oulad'] = df_oulad
    
    return df_uci, df_oulad

def obter_metricas_principais_uci():
    """Retorna m√©tricas principais do dataset UCI calculadas dinamicamente"""
    try:
        df_uci = carregar_dados_uci_cached()
        if df_uci.empty:
            return {
                'total_estudantes': 0,
                'media_nota_final': 0,
                'taxa_aprovacao': 0,
                'media_faltas': 0,
                'distribuicao_genero': {},
                'media_tempo_estudo': 0,
                'correlacao_g1_g3': 0,
                'correlacao_g2_g3': 0,
                'estudantes_alcool_baixo': 0,
                'estudantes_alcool_alto': 0
            }
        
        # Calcular m√©tricas reais
        total_estudantes = len(df_uci)
        media_nota_final = df_uci['G3'].mean() if 'G3' in df_uci.columns else 0
        taxa_aprovacao = (df_uci['G3'] >= 10).mean() * 100 if 'G3' in df_uci.columns else 0
        media_faltas = df_uci['absences'].mean() if 'absences' in df_uci.columns else 0
        
        # Distribui√ß√£o de g√™nero
        if 'sex' in df_uci.columns:
            dist_genero = df_uci['sex'].value_counts(normalize=True) * 100
            distribuicao_genero = {k: round(v, 1) for k, v in dist_genero.to_dict().items()}
        else:
            distribuicao_genero = {}
        
        # Tempo de estudo m√©dio - converter strings para n√∫meros
        if 'studytime' in df_uci.columns:
            # Mapear strings para n√∫meros para calcular m√©dia
            studytime_map = {'<2h': 1, '2-5h': 2, '5-10h': 3, '>10h': 4}
            studytime_numeric = df_uci['studytime'].map(studytime_map)
            media_tempo_estudo = studytime_numeric.mean()
        else:
            media_tempo_estudo = 0
        
        # Correla√ß√µes
        correlacao_g1_g3 = df_uci[['G1', 'G3']].corr().iloc[0, 1] if all(col in df_uci.columns for col in ['G1', 'G3']) else 0
        correlacao_g2_g3 = df_uci[['G2', 'G3']].corr().iloc[0, 1] if all(col in df_uci.columns for col in ['G2', 'G3']) else 0
        
        # Consumo de √°lcool
        if 'Dalc' in df_uci.columns:
            alcool_baixo = (df_uci['Dalc'] <= 2).mean() * 100
            alcool_alto = (df_uci['Dalc'] >= 4).mean() * 100
        else:
            alcool_baixo = 0
            alcool_alto = 0
        
        return {
            'total_estudantes': total_estudantes,
            'media_nota_final': round(media_nota_final, 2),
            'taxa_aprovacao': round(taxa_aprovacao, 1),
            'media_faltas': round(media_faltas, 1),
            'distribuicao_genero': distribuicao_genero,
            'media_tempo_estudo': round(media_tempo_estudo, 1),
            'correlacao_g1_g3': round(correlacao_g1_g3, 2),
            'correlacao_g2_g3': round(correlacao_g2_g3, 2),
            'estudantes_alcool_baixo': round(alcool_baixo, 1),
            'estudantes_alcool_alto': round(alcool_alto, 1)
        }
    except Exception as e:
        st.warning(f"Erro ao calcular m√©tricas UCI: {e}")
        return {
            'total_estudantes': 0,
            'media_nota_final': 0,
            'taxa_aprovacao': 0,
            'media_faltas': 0,
            'distribuicao_genero': {},
            'media_tempo_estudo': 0,
            'correlacao_g1_g3': 0,
            'correlacao_g2_g3': 0,
            'estudantes_alcool_baixo': 0,
            'estudantes_alcool_alto': 0
        }

def obter_metricas_principais_oulad():
    """Retorna m√©tricas principais do dataset OULAD calculadas dinamicamente"""
    try:
        df_oulad = carregar_dados_oulad_cached()
        if df_oulad.empty:
            return {
                'total_estudantes': 0,
                'taxa_aprovacao': 0,
                'media_cliques': 0,
                'distribuicao_genero': {},
                'faixa_etaria_principal': 'N/A',
                'atividade_mais_comum': 'N/A',
                'regiao_principal': 'N/A',
                'estudantes_aprovados': 0,
                'estudantes_distincao': 0,
                'estudantes_reprovados': 0
            }
        
        # Calcular m√©tricas reais
        # Usar nunique() para contar estudantes √∫nicos, n√£o registros
        if 'id_student' in df_oulad.columns:
            total_estudantes = df_oulad['id_student'].nunique()
        else:
            total_estudantes = len(df_oulad)  # Fallback se n√£o houver coluna id_student
        
        media_cliques = df_oulad['clicks'].mean() if 'clicks' in df_oulad.columns else 0
        
        # Taxa de aprova√ß√£o
        if 'final_result' in df_oulad.columns:
            taxa_aprovacao = (df_oulad['final_result'] == 'Pass').mean() * 100
            estudantes_aprovados = taxa_aprovacao
            estudantes_distincao = (df_oulad['final_result'] == 'Distinction').mean() * 100
            estudantes_reprovados = (df_oulad['final_result'] == 'Fail').mean() * 100
        else:
            taxa_aprovacao = 0
            estudantes_aprovados = 0
            estudantes_distincao = 0
            estudantes_reprovados = 0
        
        # Distribui√ß√£o de g√™nero
        if 'gender' in df_oulad.columns and 'id_student' in df_oulad.columns:
            dist_genero = df_oulad.groupby('gender')['id_student'].nunique()
            total_estudantes = df_oulad['id_student'].nunique()
            dist_genero_pct = (dist_genero / total_estudantes * 100)
            distribuicao_genero = {k: round(v, 1) for k, v in dist_genero_pct.to_dict().items()}
        else:
            distribuicao_genero = {}
        
        # Faixa et√°ria principal
        if 'age_band' in df_oulad.columns and 'id_student' in df_oulad.columns:
            # Encontrar a faixa et√°ria com mais estudantes √∫nicos
            idade_counts = df_oulad.groupby('age_band')['id_student'].nunique()
            faixa_etaria_principal = idade_counts.idxmax() if not idade_counts.empty else 'N/A'
        else:
            faixa_etaria_principal = 'N/A'
        
        # Atividade mais comum
        if 'activity_type' in df_oulad.columns:
            atividade_mais_comum = df_oulad['activity_type'].mode().iloc[0] if not df_oulad['activity_type'].mode().empty else 'N/A'
        else:
            atividade_mais_comum = 'N/A'
        
        # Regi√£o principal
        if 'region' in df_oulad.columns and 'id_student' in df_oulad.columns:
            # Encontrar a regi√£o com mais estudantes √∫nicos
            regiao_counts = df_oulad.groupby('region')['id_student'].nunique()
            regiao_principal = regiao_counts.idxmax() if not regiao_counts.empty else 'N/A'
        else:
            regiao_principal = 'N/A'
        
        return {
            'total_estudantes': total_estudantes,
            'taxa_aprovacao': round(taxa_aprovacao, 1),
            'media_cliques': round(media_cliques, 2),
            'distribuicao_genero': distribuicao_genero,
            'faixa_etaria_principal': faixa_etaria_principal,
            'atividade_mais_comum': atividade_mais_comum,
            'regiao_principal': regiao_principal,
            'estudantes_aprovados': round(estudantes_aprovados, 1),
            'estudantes_distincao': round(estudantes_distincao, 1),
            'estudantes_reprovados': round(estudantes_reprovados, 1)
        }
    except Exception as e:
        st.warning(f"Erro ao calcular m√©tricas OULAD: {e}")
        return {
            'total_estudantes': 0,
            'taxa_aprovacao': 0,
            'media_cliques': 0,
            'distribuicao_genero': {},
            'faixa_etaria_principal': 'N/A',
            'atividade_mais_comum': 'N/A',
            'regiao_principal': 'N/A',
            'estudantes_aprovados': 0,
            'estudantes_distincao': 0,
            'estudantes_reprovados': 0
        }

def calcular_metricas_uci(df_uci):
    """Calcula m√©tricas principais para o dataset UCI"""
    if df_uci.empty:
        return {}
    
    metricas = {
        'total_alunos': len(df_uci),
        'media_nota_final': df_uci['G3'].mean() if 'G3' in df_uci.columns else 0,
        'taxa_aprovacao': (df_uci['G3'] >= 10).mean() * 100 if 'G3' in df_uci.columns else 0,
        'media_faltas': df_uci['absences'].mean() if 'absences' in df_uci.columns else 0,
        'media_tempo_estudo': df_uci['studytime'].map({'<2h': 1, '2-5h': 2, '5-10h': 3, '>10h': 4}).mean() if 'studytime' in df_uci.columns else 0,
        'distribuicao_genero': df_uci['sex'].value_counts().to_dict() if 'sex' in df_uci.columns else {},
        'correlacao_notas': df_uci[['G1', 'G2', 'G3']].corr().to_dict() if all(col in df_uci.columns for col in ['G1', 'G2', 'G3']) else {}
    }
    return metricas

def calcular_metricas_oulad(df_oulad):
    """Calcula m√©tricas principais para o dataset OULAD"""
    if df_oulad.empty:
        return {}
    
    metricas = {
        'total_estudantes': df_oulad['id_student'].nunique() if 'id_student' in df_oulad.columns else len(df_oulad),
        'media_cliques': df_oulad['clicks'].mean() if 'clicks' in df_oulad.columns else 0,
        'taxa_aprovacao': (df_oulad['final_result'] == 'Pass').mean() * 100 if 'final_result' in df_oulad.columns else 0,
        'distribuicao_genero': df_oulad.groupby('gender')['id_student'].nunique().to_dict() if 'gender' in df_oulad.columns and 'id_student' in df_oulad.columns else {},
        'distribuicao_idade': df_oulad.groupby('age_band')['id_student'].nunique().to_dict() if 'age_band' in df_oulad.columns and 'id_student' in df_oulad.columns else {},
        'atividade_mais_comum': df_oulad['activity_type'].mode().iloc[0] if 'activity_type' in df_oulad.columns else 'N/A',
        'regiao_mais_comum': df_oulad['region'].mode().iloc[0] if 'region' in df_oulad.columns else 'N/A'
    }
    return metricas

def gerar_metricas_consolidadas(df_uci, df_oulad):
    """Gera m√©tricas consolidadas para o dashboard"""
    metricas_uci = calcular_metricas_uci(df_uci)
    metricas_oulad = calcular_metricas_oulad(df_oulad)
    
    # M√©tricas consolidadas
    total_estudantes = metricas_uci.get('total_alunos', 0) + metricas_oulad.get('total_estudantes', 0)
    taxa_aprovacao_geral = np.mean([
        metricas_uci.get('taxa_aprovacao', 0),
        metricas_oulad.get('taxa_aprovacao', 0)
    ])
    
    return {
        'total_estudantes_geral': total_estudantes,
        'taxa_aprovacao_geral': taxa_aprovacao_geral,
        'metricas_uci': metricas_uci,
        'metricas_oulad': metricas_oulad
    }

def criar_sidebar_dashboard():
    """Cria a barra lateral do dashboard"""
    with st.sidebar:
        st.markdown("### üìä Dashboard Educacional")
        
        # Carregar m√©tricas din√¢micas
        metricas_uci = obter_metricas_principais_uci()
        metricas_oulad = obter_metricas_principais_oulad()
        
        st.markdown("### üìö Sobre os Datasets")
        st.markdown(f"""
        **üìö UCI Dataset:**
        - Escolas p√∫blicas portuguesas
        - {metricas_uci['total_estudantes']:,} estudantes
        - Dados demogr√°ficos e acad√™micos
        - An√°lise de fatores de sucesso
        """)
        
        st.markdown(f"""
        **üåê OULAD Dataset:**
        - Plataforma de aprendizado online
        - {metricas_oulad['total_estudantes']:,} estudantes
        - Dados de engajamento digital
        - An√°lise de atividades online
        """)
        
        st.markdown("---")
        st.markdown("### üìà M√©tricas R√°pidas")
        
        # M√©tricas UCI
        st.metric(
            "üéì UCI - Aprova√ß√£o",
            f"{metricas_uci['taxa_aprovacao']:.1f}%",
            help="Taxa de aprova√ß√£o nas escolas p√∫blicas"
        )
        
        st.metric(
            "üìä UCI - M√©dia Notas",
            f"{metricas_uci['media_nota_final']:.1f}",
            help="M√©dia das notas finais"
        )
        
        # M√©tricas OULAD
        st.metric(
            "üåê OULAD - Aprova√ß√£o",
            f"{metricas_oulad['taxa_aprovacao']:.1f}%",
            help="Taxa de aprova√ß√£o na plataforma online"
        )
        
        st.metric(
            "üñ±Ô∏è OULAD - Engajamento",
            f"{metricas_oulad['media_cliques']:.1f}",
            help="M√©dia de cliques por estudante"
        )
        
        st.markdown("---")
        st.markdown("### üí° Principais Insights")
        
        # Insights din√¢micos baseados nos dados reais
        insights_text = []
        
        if metricas_uci['correlacao_g1_g3'] > 0.7:
            insights_text.append(f"**Correla√ß√£o forte** entre notas bimestrais e finais ({metricas_uci['correlacao_g1_g3']:.2f})")
        
        if metricas_uci['distribuicao_genero']:
            genero_maioria = max(metricas_uci['distribuicao_genero'], key=metricas_uci['distribuicao_genero'].get)
            insights_text.append(f"**G√™nero predominante**: {genero_maioria} ({metricas_uci['distribuicao_genero'][genero_maioria]:.1f}%)")
        
        if metricas_uci['media_faltas'] > 0:
            insights_text.append(f"**M√©dia de faltas**: {metricas_uci['media_faltas']:.1f} por estudante")
        
        if metricas_uci['media_tempo_estudo'] > 0:
            insights_text.append(f"**Tempo de estudo m√©dio**: {metricas_uci['media_tempo_estudo']:.1f}h/semana")
        
        if metricas_oulad['atividade_mais_comum'] != 'N/A':
            insights_text.append(f"**Atividade mais comum**: {metricas_oulad['atividade_mais_comum']}")
        
        if insights_text:
            for insight in insights_text:
                st.markdown(f"- {insight}")
        else:
            st.markdown("""
            - **Correla√ß√£o forte** entre notas bimestrais e finais
            - **G√™nero influencia** desempenho acad√™mico
            - **Faltas impactam** negativamente o desempenho
            - **Tempo de estudo** ideal: 5-10h/semana
            - **Atividades online** mais efetivas: outcontent, forumng
            """)
        
        st.markdown("---")
        st.markdown("### ‚ÑπÔ∏è Informa√ß√µes")
        st.markdown("**Mestrado em Tecnologia Educacional - UFC**")
    
    return None, None  # Retorna None para manter compatibilidade

def exibir_cartoes_informativos():
    """Exibe cart√µes informativos com m√©tricas principais"""
    metricas_uci = obter_metricas_principais_uci()
    metricas_oulad = obter_metricas_principais_oulad()
    
    # Cart√µes principais
    st.markdown("## üìä M√©tricas Principais")
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric(
            "üéì Total de Estudantes", 
            f"{metricas_uci['total_estudantes'] + metricas_oulad['total_estudantes']:,}",
            help="Soma dos estudantes dos datasets UCI e OULAD"
        )
    
    with col2:
        taxa_geral = (metricas_uci['taxa_aprovacao'] + metricas_oulad['taxa_aprovacao']) / 2
        st.metric(
            "‚úÖ Taxa de Aprova√ß√£o Geral", 
            f"{taxa_geral:.1f}%",
            help="M√©dia das taxas de aprova√ß√£o dos dois datasets"
        )
    
    with col3:
        st.metric(
            "üìö M√©dia de Notas (UCI)", 
            f"{metricas_uci['media_nota_final']:.1f}",
            help="M√©dia das notas finais no dataset UCI"
        )
    
    with col4:
        st.metric(
            "üñ±Ô∏è M√©dia de Cliques (OULAD)", 
            f"{metricas_oulad['media_cliques']:.1f}",
            help="M√©dia de cliques por estudante no dataset OULAD"
        )

def exibir_cartoes_detalhados():
    """Exibe cart√µes detalhados para cada dataset"""
    metricas_uci = obter_metricas_principais_uci()
    metricas_oulad = obter_metricas_principais_oulad()
    
    # Cart√µes UCI
    st.markdown("### üìö Dataset UCI - Escolas P√∫blicas Portuguesas")
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric(
            "üë• Total de Estudantes", 
            f"{metricas_uci['total_estudantes']:,}",
            help="Estudantes de escolas p√∫blicas portuguesas"
        )
    
    with col2:
        st.metric(
            "‚úÖ Taxa de Aprova√ß√£o", 
            f"{metricas_uci['taxa_aprovacao']:.1f}%",
            help="Percentual de estudantes aprovados"
        )
    
    with col3:
        st.metric(
            "üìä M√©dia de Faltas", 
            f"{metricas_uci['media_faltas']:.1f}",
            help="N√∫mero m√©dio de faltas por estudante"
        )
    
    with col4:
        st.metric(
            "‚è∞ Tempo de Estudo", 
            f"{metricas_uci['media_tempo_estudo']:.1f}h/semana",
            help="Tempo m√©dio de estudo semanal"
        )
    
    # Cart√µes OULAD
    st.markdown("### üåê Dataset OULAD - Plataforma de Aprendizado Online")
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric(
            "üë• Total de Estudantes", 
            f"{metricas_oulad['total_estudantes']:,}",
            help="Estudantes da plataforma online"
        )
    
    with col2:
        st.metric(
            "‚úÖ Taxa de Aprova√ß√£o", 
            f"{metricas_oulad['taxa_aprovacao']:.1f}%",
            help="Percentual de estudantes aprovados"
        )
    
    with col3:
        st.metric(
            "üèÜ Distin√ß√£o", 
            f"{metricas_oulad['estudantes_distincao']:.1f}%",
            help="Percentual de estudantes com distin√ß√£o"
        )
    
    with col4:
        st.metric(
            "üñ±Ô∏è Engajamento", 
            f"{metricas_oulad['media_cliques']:.1f} cliques",
            help="M√©dia de cliques por estudante"
        )

def obter_insights_uci():
    """Retorna insights principais do dataset UCI baseados em dados reais"""
    metricas = obter_metricas_principais_uci()
    
    insights = []
    
    # Correla√ß√£o forte
    if metricas['correlacao_g1_g3'] > 0.7 and metricas['correlacao_g2_g3'] > 0.7:
        insights.append(f"üéØ **Correla√ß√£o Forte**: Notas do 1¬∫ e 2¬∫ bimestre t√™m correla√ß√£o de {metricas['correlacao_g1_g3']:.2f} e {metricas['correlacao_g2_g3']:.2f} com a nota final")
    
    # G√™nero
    if metricas['distribuicao_genero']:
        genero_maioria = max(metricas['distribuicao_genero'], key=metricas['distribuicao_genero'].get)
        genero_menor = min(metricas['distribuicao_genero'], key=metricas['distribuicao_genero'].get)
        insights.append(f"üë• **G√™nero**: Estudantes do sexo {genero_maioria} representam {metricas['distribuicao_genero'][genero_maioria]:.1f}% vs {genero_menor} com {metricas['distribuicao_genero'][genero_menor]:.1f}%")
    
    # Consumo de √°lcool
    if metricas['estudantes_alcool_baixo'] > 0:
        insights.append(f"üç∑ **Consumo de √Ålcool**: {metricas['estudantes_alcool_baixo']:.1f}% dos estudantes t√™m baixo consumo, com melhor desempenho acad√™mico")
    
    # Tempo de estudo
    if metricas['media_tempo_estudo'] > 0:
        insights.append(f"üìö **Tempo de Estudo**: M√©dia de {metricas['media_tempo_estudo']:.1f}h/semana por estudante")
    
    # Faltas
    if metricas['media_faltas'] > 0:
        insights.append(f"‚ùå **Faltas**: M√©dia de {metricas['media_faltas']:.1f} faltas por estudante")
    
    # Taxa de aprova√ß√£o
    if metricas['taxa_aprovacao'] > 0:
        insights.append(f"‚úÖ **Aprova√ß√£o**: Taxa de aprova√ß√£o de {metricas['taxa_aprovacao']:.1f}%")
    
    # M√©dia de notas
    if metricas['media_nota_final'] > 0:
        insights.append(f"üìä **Desempenho**: M√©dia de notas finais de {metricas['media_nota_final']:.1f}")
    
    return {
        'titulo': 'üìö Principais Insights - Dataset UCI',
        'insights': insights if insights else [
            "üéØ **Correla√ß√£o Forte**: Notas do 1¬∫ e 2¬∫ bimestre t√™m correla√ß√£o forte com a nota final",
            "üë• **G√™nero**: Distribui√ß√£o equilibrada entre g√™neros",
            "üìö **Tempo de Estudo**: Fator importante para o desempenho acad√™mico",
            "‚ùå **Faltas**: Impactam negativamente o desempenho",
            "üë®‚Äçüë©‚Äçüëß‚Äçüë¶ **Fam√≠lia**: Escolaridade dos pais influencia o desempenho dos filhos"
        ]
    }

def obter_insights_oulad():
    """Retorna insights principais do dataset OULAD baseados em dados reais"""
    metricas = obter_metricas_principais_oulad()
    
    insights = []
    
    # Demografia
    if metricas['distribuicao_genero']:
        genero_maioria = max(metricas['distribuicao_genero'], key=metricas['distribuicao_genero'].get)
        insights.append(f"üë• **Demografia**: {metricas['distribuicao_genero'][genero_maioria]:.1f}% s√£o do sexo {genero_maioria}")
    
    if metricas['faixa_etaria_principal'] != 'N/A':
        insights.append(f"üë• **Faixa Et√°ria**: Faixa et√°ria predominante de {metricas['faixa_etaria_principal']}")
    
    # Desempenho
    if metricas['taxa_aprovacao'] > 0:
        insights.append(f"üèÜ **Alto Desempenho**: {metricas['taxa_aprovacao']:.1f}% de aprova√ß√£o")
    
    if metricas['estudantes_distincao'] > 0:
        insights.append(f"üèÜ **Distin√ß√£o**: {metricas['estudantes_distincao']:.1f}% obtendo distin√ß√£o")
    
    # Engajamento
    if metricas['media_cliques'] > 0:
        insights.append(f"üñ±Ô∏è **Engajamento**: M√©dia de {metricas['media_cliques']:.1f} cliques por estudante, indicando engajamento moderado")
    
    # Atividades
    if metricas['atividade_mais_comum'] != 'N/A':
        insights.append(f"üìö **Atividades**: '{metricas['atividade_mais_comum']}' √© a atividade mais realizada")
    
    # Regi√£o
    if metricas['regiao_principal'] != 'N/A':
        insights.append(f"üåç **Regi√£o**: {metricas['regiao_principal']} concentra a maior parte dos estudantes")
    
    # Distribui√ß√£o de resultados
    if metricas['estudantes_reprovados'] > 0:
        insights.append(f"üìä **Distribui√ß√£o**: Aprova√ß√£o supera largamente outras categorias (reprova√ß√£o: {metricas['estudantes_reprovados']:.1f}%)")
    
    # Total de estudantes
    if metricas['total_estudantes'] > 0:
        insights.append(f"üë• **Total**: {metricas['total_estudantes']:,} estudantes analisados")
    
    return {
        'titulo': 'üåê Principais Insights - Dataset OULAD',
        'insights': insights if insights else [
            "üë• **Demografia**: Distribui√ß√£o equilibrada entre g√™neros",
            "üèÜ **Alto Desempenho**: Boa taxa de aprova√ß√£o geral",
            "üñ±Ô∏è **Engajamento**: N√≠vel moderado de engajamento na plataforma",
            "üìö **Atividades**: Diversas atividades dispon√≠veis",
            "üåç **Regi√£o**: Distribui√ß√£o geogr√°fica variada",
            "üìä **Distribui√ß√£o**: Resultados positivos predominam"
        ]
    }

@st.cache_data(ttl=3600)  # Cache por 1 hora
def carregar_modelo_uci():
    """Carrega o modelo UCI com cache"""
    try:
        # Tentar diferentes caminhos para o arquivo pickle
        possible_paths = [
            '../uci.pkl',
            '../../uci.pkl',
            Path(__file__).parent.parents[1] / "uci.pkl",
            'uci.pkl'
        ]
        
        model = None
        for path in possible_paths:
            p = Path(path)
            if p.is_file():
                try:
                    with p.open("rb") as f:
                        model = pickle.load(f)
                    break
                except Exception as e:
                    continue
        
        if model is None:
            raise FileNotFoundError(f"Arquivo uci.pkl n√£o encontrado em nenhum dos caminhos: {possible_paths}")
        
        return model
    except Exception as e:
        st.warning(f"Erro ao carregar modelo UCI: {e}")
        return None

@st.cache_data(ttl=3600)  # Cache por 1 hora
def carregar_modelo_oulad():
    """Carrega o modelo OULAD com cache"""
    try:
        # Tentar diferentes caminhos para o arquivo pickle
        possible_paths = [
            '../oulad.pkl',
            '../../oulad.pkl',
            Path(__file__).parent.parents[1] / "oulad.pkl",
            'oulad.pkl'
        ]
        
        model = None
        for path in possible_paths:
            p = Path(path)
            if p.is_file():
                try:
                    with p.open("rb") as f:
                        model = pickle.load(f)
                    break
                except Exception as e:
                    continue
        
        if model is None:
            raise FileNotFoundError(f"Arquivo oulad.pkl n√£o encontrado em nenhum dos caminhos: {possible_paths}")
        
        return model
    except Exception as e:
        st.warning(f"Erro ao carregar modelo OULAD: {e}")
        return None

@st.cache_data(ttl=3600)  # Cache por 1 hora (UCI √© menor)
def calcular_feature_importance_uci():
    """Calcula feature importance real para UCI com otimiza√ß√µes"""
    try:
        from sklearn.inspection import permutation_importance
        from sklearn.model_selection import train_test_split
        
        # Indicador de progresso
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        status_text.text("üîÑ Carregando dados UCI...")
        progress_bar.progress(20)
        
        # Carregar dados UCI
        df_uci = carregar_uci_dados()
        
        status_text.text("üîÑ Preparando dados...")
        progress_bar.progress(40)
        
        # Preparar dados como nas p√°ginas individuais
        Y = df_uci['G3']
        X = df_uci.drop('G3', axis=1)
        
        # Dividir dados
        X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)
        
        status_text.text("üîÑ Carregando modelo...")
        progress_bar.progress(60)
        
        # Carregar modelo treinado
        model = carregar_modelo_uci()
        if model is None:
            progress_bar.empty()
            status_text.empty()
            return pd.DataFrame()
        
        status_text.text("üîÑ Calculando feature importance...")
        progress_bar.progress(80)
        
        # OTIMIZA√á√ÉO: Usar todos os cores dispon√≠veis
        result = permutation_importance(
            model, X_test, y_test, 
            n_repeats=10,  # Manter 10 para UCI (√© pequeno)
            random_state=42, 
            n_jobs=-1  # Usar todos os cores dispon√≠veis
        )
        sorted_idx = result.importances_mean.argsort()
        
        status_text.text("‚úÖ Finalizando...")
        progress_bar.progress(95)
        
        # Criar DataFrame com resultados reais
        features = X_test.columns[sorted_idx]
        importance = result.importances_mean[sorted_idx]
        
        df_result = pd.DataFrame({
            'feature': features,
            'importance': importance
        }).sort_values('importance', ascending=True)
        
        # Limpar indicadores
        progress_bar.empty()
        status_text.empty()
        
        return df_result
        
    except Exception as e:
        st.warning(f"Erro ao calcular feature importance UCI: {e}")
        return pd.DataFrame()

@st.cache_data(ttl=7200)  # Cache por 2 horas (OULAD √© pesado)
def calcular_feature_importance_oulad():
    """Calcula feature importance real para OULAD com otimiza√ß√µes"""
    try:
        from sklearn.inspection import permutation_importance
        from sklearn.model_selection import train_test_split
        
        # Indicador de progresso
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        status_text.text("üîÑ Carregando dados OULAD...")
        progress_bar.progress(10)
        
        # Carregar dados OULAD
        df_oulad = carregar_oulad_dados()
        
        # AMOSTRAGEM: Usar apenas 50k registros para OULAD (muito mais r√°pido)
        if len(df_oulad) > 50000:
            df_oulad = df_oulad.sample(n=50000, random_state=42)
            st.info("üìä Usando amostra de 50k registros para an√°lise mais r√°pida")
        
        status_text.text("üîÑ Preparando dados...")
        progress_bar.progress(30)
        
        # Preparar dados como nas p√°ginas individuais
        Y = df_oulad['final_result']
        X = df_oulad.loc[:, df_oulad.columns != 'final_result']
        
        # Remover colunas irrelevantes
        X = X.drop(['id_student', 'id_site', 'id_assessment', 'code_module', 'code_presentation', 'code_module_y', 'code_module_x'], axis=1, errors='ignore')
        
        status_text.text("üîÑ Dividindo dados...")
        progress_bar.progress(50)
        
        # Dividir dados
        X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)
        
        # Carregar modelo treinado
        model = carregar_modelo_oulad()
        if model is None:
            progress_bar.empty()
            status_text.empty()
            return pd.DataFrame()
        
        status_text.text("üîÑ Limpando dados de teste...")
        progress_bar.progress(70)
        
        # Limpar dados de teste
        nan_rows_test = y_test.isnull()
        X_test_cleaned = X_test[~nan_rows_test].copy()
        y_test_cleaned = y_test[~nan_rows_test].copy()
        
        status_text.text("üîÑ Calculando feature importance...")
        progress_bar.progress(85)
        
        # OTIMIZA√á√ÉO: Menos repeti√ß√µes e mais jobs
        result = permutation_importance(
            model, X_test_cleaned, y_test_cleaned, 
            n_repeats=5,  # Reduzido de 10 para 5
            random_state=42, 
            n_jobs=-1  # Usar todos os cores dispon√≠veis
        )
        sorted_idx = result.importances_mean.argsort()
        
        status_text.text("‚úÖ Finalizando...")
        progress_bar.progress(95)
        
        # Criar DataFrame com resultados reais
        features = X_test_cleaned.columns[sorted_idx]
        importance = result.importances_mean[sorted_idx]
        
        df_result = pd.DataFrame({
            'feature': features,
            'importance': importance
        }).sort_values('importance', ascending=True)
        
        # Limpar indicadores
        progress_bar.empty()
        status_text.empty()
        
        return df_result
        
    except Exception as e:
        st.warning(f"Erro ao calcular feature importance OULAD: {e}")
        return pd.DataFrame()

def criar_grafico_feature_importance_uci():
    """Cria gr√°fico de feature importance para UCI"""
    df_importance = calcular_feature_importance_uci()
    if df_importance.empty:
        return None
    
    fig, ax = plt.subplots(figsize=(10, 8))
    bars = ax.barh(df_importance['feature'], df_importance['importance'], color='skyblue')
    ax.set_title('Import√¢ncia das Features - Dataset UCI', fontsize=14, fontweight='bold')
    ax.set_xlabel('Import√¢ncia')
    ax.set_ylabel('Features')
    
    # Adicionar valores nas barras
    for i, (bar, importance) in enumerate(zip(bars, df_importance['importance'])):
        ax.text(bar.get_width() + 0.01, bar.get_y() + bar.get_height()/2, 
                f'{importance:.3f}', va='center', fontsize=10)
    
    plt.tight_layout()
    return fig

def criar_grafico_feature_importance_oulad():
    """Cria gr√°fico de feature importance para OULAD"""
    df_importance = calcular_feature_importance_oulad()
    if df_importance.empty:
        return None
    
    fig, ax = plt.subplots(figsize=(10, 8))
    bars = ax.barh(df_importance['feature'], df_importance['importance'], color='lightcoral')
    ax.set_title('Import√¢ncia das Features - Dataset OULAD', fontsize=14, fontweight='bold')
    ax.set_xlabel('Import√¢ncia')
    ax.set_ylabel('Features')
    
    # Adicionar valores nas barras
    for i, (bar, importance) in enumerate(zip(bars, df_importance['importance'])):
        ax.text(bar.get_width() + 0.01, bar.get_y() + bar.get_height()/2, 
                f'{importance:.3f}', va='center', fontsize=10)
    
    plt.tight_layout()
    return fig

def criar_secao_pygwalker():
    """Cria se√ß√£o opcional para PyGWalker com sele√ß√£o de dataset"""
    st.markdown("---")
    st.markdown("### üîç An√°lise Interativa com PyGWalker")
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        dataset_selecionado = st.selectbox(
            "Selecione o dataset para an√°lise:",
            ["UCI", "OULAD"],
            help="Escolha qual dataset analisar interativamente"
        )
    
    with col2:
        usar_pygwalker_uci = st.checkbox(
            "Ativar PyGWalker UCI", 
            value=False,
            help="Permite an√°lise interativa dos dados UCI"
        )

        usar_pygwalker_oulad = st.checkbox(
            "Ativar PyGWalker OULAD", 
            value=False,
            help="Permite an√°lise interativa dos dados OULAD"
        )
    if usar_pygwalker_uci:
        try:
            import pygwalker as pyg
            from pygwalker.api.streamlit import StreamlitRenderer
            
            # Carregar dados baseado na sele√ß√£o
            if dataset_selecionado == "UCI":
                if 'df_uci' in st.session_state and not st.session_state['df_uci'].empty:
                    st.info("üìä Carregando PyGWalker com dados UCI...")
                    df = st.session_state['df_uci']
                else:
                    st.info("üìä Carregando dados UCI do arquivo...")
                    df = carregar_uci_dados()
            else:  # OULAD
                if 'df_oulad' in st.session_state and not st.session_state['df_oulad'].empty:
                    st.info("üìä Carregando PyGWalker com dados OULAD...")
                    df = st.session_state['df_oulad']
                else:
                    st.info("üìä Carregando dados OULAD do arquivo...")
                    df = carregar_oulad_dados()
            
            # Verificar se os dados foram carregados
            if df is not None and not df.empty:
                # Criar renderer do PyGWalker
                renderer = StreamlitRenderer(df, spec="./gw0.json", debug=False)
                renderer.render_explore()
            else:
                st.warning(f"‚ö†Ô∏è Nenhum dado dispon√≠vel para {dataset_selecionado}. Verifique se os arquivos de dados existem.")
                
        except ImportError:
            st.error("‚ùå PyGWalker n√£o est√° instalado. Execute: `pip install pygwalker`")
        except Exception as e:
            st.error(f"‚ùå Erro ao carregar PyGWalker: {e}")
    else:
        st.info(f"üí° Marque a op√ß√£o acima para ativar a an√°lise interativa com PyGWalker para o dataset {dataset_selecionado}")

    if usar_pygwalker_oulad:
        try:
            import pygwalker as pyg
            from pygwalker.api.streamlit import StreamlitRenderer
            
            # Verificar se h√° dados dispon√≠veis
            if 'df_oulad' in st.session_state and not st.session_state['df_oulad'].empty:
                st.info("üìä Carregando PyGWalker com dados OULAD...")
                df = st.session_state['df_oulad']
                
                # Criar renderer do PyGWalker
                renderer = StreamlitRenderer(df, spec="./gw0.json", debug=False)
                renderer.render_explore()
                
            else:
                st.warning("‚ö†Ô∏è Nenhum dado dispon√≠vel para an√°lise interativa. Navegue para as p√°ginas de an√°lise primeiro.")
            
        except ImportError:
            st.error("‚ùå PyGWalker n√£o est√° instalado. Execute: `pip install pygwalker`")
        except Exception as e:
            st.error(f"‚ùå Erro ao carregar PyGWalker: {e}")
        else:
            st.info("üí° Marque a op√ß√£o acima para ativar a an√°lise interativa com PyGWalker")
