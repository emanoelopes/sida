from pathlib import Path
import streamlit as st
import pandas as pd
import os
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
import pickle
from src.openai_interpreter import criar_rodape_sidebar

st.set_page_config(
    page_title="An√°lise Explorat√≥ria dos Dados - UCI",
    page_icon="üìä",
    layout="wide",
    initial_sidebar_state="expanded",
    )

st.title("Informa√ß√µes B√°sicas do Conjunto de Dados UCI")
st.divider()

"""
O UCI Machine Learning Repository √© uma fonte valiosa de conjuntos de dados para a comunidade de aprendizado de m√°quina, promovendo a pesquisa e o avan√ßo na √°rea de ci√™ncia de dados.
"""

datasets_uci_path = Path(__file__).parent.parents[1] / 'datasets' / 'uci_data'
#st.write(f"Path dos datasets: {datasets_uci_path}")

# Portugu√™s
por_path = os.path.join(datasets_uci_path, 'student-por.csv')
por = pd.read_csv(por_path, sep=';')
# Matem√°tica
mat_path = os.path.join(datasets_uci_path, 'student-mat.csv')
mat = pd.read_csv(mat_path, sep=';')

# Adicionando coluna com o conjunto de dados de origem
mat['origem'] = 'mat'
por['origem'] = 'por'

# Concatenando os dataframes

@st.cache_data(ttl=3600)  # Cache por 1 hora
def concat():
    df = pd.concat([mat, por])
    return df

df = concat()

st.session_state['df_uci'] = df
# Transformando valores e tipos de dados
df['traveltime'] = df['traveltime'].map({1: '<15m', 2: '15-30m', 3: '30-1h', 4: '>1h'}).astype(str)
df['studytime'] = df['studytime'].map({1: '<2h', 2: '2-5h', 3: '5-10h', 4: '>10h'}).astype(str)
df[['Medu','Fedu','famrel','goout','Dalc','Walc','health']] = \
df[['Medu','Fedu','famrel','goout','Dalc','Walc','health']].astype('object')

st.markdown("## Explorando os valores num√©ricos")
numeric_df = df.select_dtypes('number')


# Create visualization selection in sidebar
with st.sidebar:
    st.markdown("### Distribui√ß√µes dos dados num√©ricos")
    viz_type = st.selectbox(
        "Tipo de Visualiza√ß√£o",
        ["Box Plot", "Histograma", "Violin Plot"]
    )
    st.markdown("---")
    st.markdown("## Informa√ß√µes")
    # Calcular estudantes √∫nicos baseado em caracter√≠sticas demogr√°ficas
    colunas_id = ['school', 'sex', 'age', 'address', 'famsize', 'Pstatus', 'Medu', 'Fedu', 'Mjob', 'Fjob', 'reason', 'guardian']
    estudantes_unicos = df[colunas_id].drop_duplicates().shape[0]
    
    st.write(f"**N√∫mero de Registros:** {df.shape[0]} (inclui estudantes em m√∫ltiplas mat√©rias)")
    st.write(f"**N√∫mero de Estudantes √önicos:** {estudantes_unicos}")
    st.write(f"**N√∫mero de Atributos:** {df.shape[1]}")
    st.write(f"**N√∫mero de Atributos Num√©ricos:** {numeric_df.shape[1]}")
    st.write(f"**N√∫mero de Atributos Categ√≥ricos:** {df.select_dtypes('object').shape[1]}")
    st.write(f"**N√∫mero de Valores Ausentes:** {df.isnull().sum().sum()}")
    st.write(f"**N√∫mero de Valores Duplicados:** {df.duplicated().sum()}")
    st.markdown("---")
    
    # Rodap√© com badges de status (igual ao da home)
    criar_rodape_sidebar()

# Create visualization section
st.markdown("### Visualiza√ß√£o das distribui√ß√µes dos dados num√©ricos ")

# Get all numeric column names
numeric_columns = numeric_df.columns.tolist()

if len(numeric_columns) > 0:
    # Determine number of rows and columns for subplots
    n_cols = min(3, len(numeric_columns))
    n_rows = (len(numeric_columns) + n_cols - 1) // n_cols
    
    # Create subplots based on selection
    fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 5*n_rows))
    if n_rows == 1:
        axes = [axes] if n_cols == 1 else axes
    else:
        axes = axes.flatten()
    
    # Mapeamento de tradu√ß√£o das colunas para portugu√™s
    traducoes_colunas = {
        'age': 'Idade',
        'G1': 'Nota do 1¬∫ Per√≠odo',
        'G2': 'Nota do 2¬∫ Per√≠odo',
        'G3': 'Nota Final',
        'absences': 'Faltas',
        'failures': 'Reprova√ß√µes Anteriores',
        'freetime': 'Tempo Livre',
        'goout': 'Sa√≠das',
        'Dalc': 'Consumo de √Ålcool (Dia)',
        'Walc': 'Consumo de √Ålcool (Fim de Semana)',
        'health': 'Sa√∫de',
        'famrel': 'Rela√ß√£o Familiar'
    }
    
    for i, col in enumerate(numeric_columns):
        # Traduzir nome da coluna para portugu√™s
        nome_traduzido = traducoes_colunas.get(col, col.title())
        
        if viz_type == "Box Plot":
            axes[i].boxplot(numeric_df[col].dropna())
            axes[i].set_title(f'Distribui√ß√£o de {nome_traduzido}')
            axes[i].set_ylabel('Valor')
        elif viz_type == "Histograma":
            axes[i].hist(numeric_df[col].dropna(), bins=30, alpha=0.7, edgecolor='black')
            axes[i].set_title(f'Distribui√ß√£o de {nome_traduzido}')
            axes[i].set_xlabel('Valor')
            axes[i].set_ylabel('Frequ√™ncia')
        elif viz_type == "Violin Plot":
            axes[i].violinplot(numeric_df[col].dropna())
            axes[i].set_title(f'Distribui√ß√£o de {nome_traduzido}')
            axes[i].set_ylabel('Valor')
        
    # Hide empty subplots
    for i in range(len(numeric_columns), len(axes)):
        axes[i].set_visible(False)
    
    plt.tight_layout()
    st.pyplot(fig)
else:
    st.write("Nenhuma coluna num√©rica encontrada.")

"""
As distribui√ß√µes dos dados num√©ricos mostram que a faixa et√°ria √©, na sua maioria, entre 15 e 19 anos. O valor m√©dio de horas semanais livres √© um pouco maior 3h. A quantidade de faltas concentra-se pr√≥ximo a zero. As notas, de um modo geral, est√£o concentradas em valores acima da mediana com uma dispers√£o aceit√°vel, coeficiente de varia√ß√£o em torno de 27%, sugerindo que a distribui√ß√£o √© razoavelmente moderada, pois mostra que os dados n√£o est√£o muito dispersos, mas ainda h√° alguma varia√ß√£o significativa nos valores analisados.
"""

st.markdown('## Distribui√ß√£o das notas')

fig, ax = plt.subplots(1, 3, figsize=(18, 5))
sns.histplot(data=df, x='G1', bins=20, kde=True, ax=ax[0])
ax[0].set_title('Distribui√ß√£o das Notas G1')
sns.histplot(data=df, x='G2', bins=20, kde=True, ax=ax[1])
ax[1].set_title('Distribui√ß√£o das Notas G2')
sns.histplot(data=df, x='G3', bins=20, kde=True, ax=ax[2])
ax[2].set_title('Distribui√ß√£o das Notas G3')
plt.tight_layout()
st.pyplot(fig)
plt.clf()   

'''
Os tr√™s histogramas de densidade mostram uma evolu√ß√£o do grupo de alunos que obtiveram nota zero ou pr√≥xima de zero.
'''

'''
## Avaliando a normalidade da classe G3
'''

import numpy as np
from scipy.stats import norm

media = df['G3'].mean()
desvio_padrao = df['G3'].std()
v_min = df['G3'].min()
v_max = df['G3'].max()

xs = np.linspace(v_min, v_max, 10_000)
ys = norm.pdf(xs, loc=media, scale=desvio_padrao)

fig, ax = plt.subplots(figsize=(18, 8))

sns.histplot(data=df, ax=ax, x='G3', binwidth=1.0, kde=True, stat='density')
ax.plot(xs, ys, color='red')

fig.suptitle('Notas finais')
st.pyplot(fig)

'''
O diagrama exibe uma distribui√ß√£o bimodal das notas finais, sinalizando a presen√ßa de uma maioria de estudantes com desempenho m√©dio e um subgrupo menor, por√©m significativo, com desempenho muito baixo ou nulo.
'''

st.markdown('## Explorando os valores categ√≥ricos')

st.session_state['cat_columns'] = df.select_dtypes('object').describe().T

st.dataframe(st.session_state['cat_columns'], width='content')


"""
Por meio da an√°lise descritiva dos dados num√©ricos e categ√≥ricos, a maioria dos estudantes √© do sexo feminino, mora em cidades em fam√≠lia com mais de tr√™s pessoas, mora com os pais, com a m√£e sendo a guardi√£ dos filhos.
"""
"""
### Distribui√ß√£o do grau de forma√ß√£o dos pais em rela√ß√£o a nota final
"""

# Boxplot
fig, axes = plt.subplots(1, 2, figsize=(18, 5)) # Correct way to define axes

sns.boxplot(data=df, x='Fedu', y='G3', ax=axes[0], palette='rainbow')  #  Use the ax at the correct index
axes[0].set_title('Distribui√ß√£o das Notas Finais por Grau de Forma√ß√£o do Pai')

sns.boxplot(data=df, x='Medu', y='G3', ax=axes[1], palette='rainbow')
axes[1].set_title('Distribui√ß√£o das Notas Finais por Grau de Forma√ß√£o da M√£e')

plt.tight_layout()
st.pyplot(fig)
# plt.clf()
'''
O gr√°fico apresenta uma rela√ß√£o direta do grau de forma√ß√£o do pai com a nota final, no entando h√° registros de estudante que alcan√ßou nota final 15 com m√£e sem educa√ß√£o formal, apesar das maiores notas serem alcan√ßadas por filhos de m√£es com n√≠vel superior.
'''

# N√≠vel de escolaridade da m√£e
fig, ax = plt.subplots(figsize=(22, 8))

sns.violinplot(data=df, x='Medu')
fig.suptitle('N√≠vel de escolaridade da m√£e', fontsize=20)
st.pyplot(fig)

'''
H√° uma concentra√ß√£o mais acentuada de m√£es com N√≠vel Superior e com Ensino Fundamental II (6¬∫ ao 9¬∫ ano). 
'''

# 1. An√°lise de correla√ß√£o entre vari√°veis num√©ricas
st.markdown("## Matriz de Correla√ß√£o")
st.write("Esta visualiza√ß√£o mostra como as vari√°veis num√©ricas se relacionam entre si.")

# Mapeamento de tradu√ß√£o das colunas para portugu√™s (reutilizando o mesmo mapeamento)
traducoes_colunas_corr = {
    'age': 'Idade',
    'G1': 'Nota do 1¬∫ Per√≠odo',
    'G2': 'Nota do 2¬∫ Per√≠odo',
    'G3': 'Nota Final',
    'absences': 'Faltas',
    'failures': 'Reprova√ß√µes Anteriores',
    'freetime': 'Tempo Livre',
    'goout': 'Sa√≠das',
    'Dalc': 'Consumo de √Ålcool (Dia)',
    'Walc': 'Consumo de √Ålcool (Fim de Semana)',
    'health': 'Sa√∫de',
    'famrel': 'Rela√ß√£o Familiar'
}

# Calcular a matriz de correla√ß√£o
corr = numeric_df.corr()

# Renomear as colunas e √≠ndices para portugu√™s
corr_renamed = corr.copy()
corr_renamed.columns = [traducoes_colunas_corr.get(col, col.title()) for col in corr.columns]
corr_renamed.index = [traducoes_colunas_corr.get(idx, idx.title()) for idx in corr.index]

# Plotar o mapa de calor
fig, ax = plt.subplots(figsize=(12, 10))
mask = np.triu(np.ones_like(corr_renamed, dtype=bool))
cmap = sns.diverging_palette(230, 20, as_cmap=True)
sns.heatmap(corr_renamed, mask=mask, cmap=cmap, vmax=1, vmin=-1, center=0,
            square=True, linewidths=.5, annot=True, fmt=".2f", ax=ax)
plt.title('Matriz de Correla√ß√£o entre Vari√°veis Num√©ricas', fontsize=15)
st.pyplot(fig)
plt.clf()

'''
A idade tem uma rela√ß√£o direta com a quantidade de faltas e falhas (notas baixas), que por sua vez t√™m uma liga√ß√£o direta com o tempo livre e aus√™ncia. As notas finais apresentam uma forte rela√ß√£o com as notas do primeiro bimestre e, ainda, com as notas do segundo bimestre, de 0,81 e 0,91, respectivamente.
'''

# 2. An√°lise da rela√ß√£o entre consumo de √°lcool e desempenho acad√™mico
st.markdown("## Rela√ß√£o entre Consumo de √Ålcool e Desempenho Acad√™mico")

fig, axes = plt.subplots(1, 2, figsize=(18, 6))
sns.boxplot(x='Dalc', y='G3', data=df, ax=axes[0], palette='tab10')
axes[0].set_title('Consumo de √Ålcool Durante a Semana vs Nota Final')
axes[0].set_xlabel('N√≠vel de Consumo de √Ålcool Durante a Semana')
axes[0].set_ylabel('Nota Final')

sns.boxplot(x='Walc', y='G3', data=df, ax=axes[1], palette='tab10')
axes[1].set_title('Consumo de √Ålcool no Final de Semana vs Nota Final')
axes[1].set_xlabel('N√≠vel de Consumo de √Ålcool no Final de Semana')
axes[1].set_ylabel('Nota Final')

plt.tight_layout()
st.pyplot(fig)
plt.clf()

'''
Estudantes com zero ou baixo consumo de √°lcool, durante a semana, alcan√ßam nota m√°xima, com m√©dia de 12,5 e com registros de nota cinco. Os alunos com alto consumo de √°lcool, durante a semana, alca√ßam notas um pouco acima de 15, mas apresentam m√©dia semelhante. Em rela√ß√£o ao consumo apenas no final de semana, os resultados s√£o mais equivalentes quando a escala alcan√ßa o valor 3, ou seja, com modera√ß√£o do consumo.
'''

# 3. An√°lise do impacto do tempo de estudo no desempenho
st.markdown("## Impacto do Tempo de Estudo no Desempenho Acad√™mico")

fig, ax = plt.subplots(figsize=(12, 6))
sns.boxplot(x='studytime', y='G3', data=df, ax=ax, palette='coolwarm')
ax.set_title('Tempo de Estudo vs Nota Final')
ax.set_xlabel('Tempo de Estudo Semanal')
ax.set_ylabel('Nota Final')
st.pyplot(fig)
plt.clf()

'''
A correla√ß√£o entre o n√∫mero de horas de estudo e a pontua√ß√£o final indica que 75% dos alunos que dedicam menos de 2 horas por semana, obt√™m uma pontua√ß√£o inferior a 13. Aqueles que estudam de 5 a 10h t√™m uma concentra√ß√£o de notas mais altas, at√© mesmo em compara√ß√£o com aqueles que estudam mais de 10h; estes foram os que obtiveram as maiores notas.
'''

# 4. An√°lise de desempenho por g√™nero
st.markdown("## Compara√ß√£o de Desempenho por G√™nero")

fig, ax = plt.subplots(figsize=(10, 6))
sns.boxplot(x='sex', y='G3', data=df, ax=ax, palette='Set1')
ax.set_title('Notas Finais por G√™nero')
ax.set_xlabel('G√™nero')
ax.set_ylabel('Nota Final')

st.pyplot(fig)
plt.clf()

'''
Uma an√°lise das notas finais de ambos os g√™neros revela que, apesar da distribui√ß√£o e da variabilidade das notas serem bastante parecidas, a mediana das notas femininas √© um pouco mais alta que a dos homens.'''

# 5. An√°lise de faltas vs desempenho
st.markdown("## Rela√ß√£o entre faltas e nota final")

# Criar categorias de faltas
# Criar um DataFrame tempor√°rio para evitar problemas de √≠ndice duplicado
temp_df = df.reset_index(drop=True).copy()

# Criar categorias de faltas
temp_df['absences_cat'] = pd.cut(temp_df['absences'], 
                           bins=[0, 5, 10, 15, 20, 100], 
                           labels=['0-5', '6-10', '11-15', '16-20', '21+'])

fig, ax = plt.subplots(figsize=(12, 6))
sns.boxplot(x='absences_cat', y='G3', data=temp_df, ax=ax, palette='Paired')
ax.set_title('Faltas vs Nota Final')
ax.set_xlabel('N√∫mero de Faltas')
ax.set_ylabel('Nota Final')

st.pyplot(fig)
plt.clf()

'''
O gr√°fico indica uma ligeira tend√™ncia de queda na nota final conforme o n√∫mero de faltas aumenta, especialmente a partir da faixa de 11-15 faltas. Estudantes que apresentam menos de 10 faltas alcan√ßam notas m√°ximas e concentram-se entre 10 e 14 pontos. As notas medianas e m√°ximas observadas demonstram uma redu√ß√£o significativa quando superior a 16 faltas.
'''

"""
## Import√¢ncia das classes em rela√ß√£o ao resultado final\
"""

st.markdown("Prepara√ß√£o dos dados para modelos de ML...")
Y = df['G3']
X = df.drop('G3', axis=1)

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)

"""
Treinando o modelo...
"""

@st.cache_data(ttl=7200)  # Cache por 2 horas
def treinar_modelo_uci(X_train, y_train):
    """Treina o modelo UCI com cache"""
    from sklearn.ensemble import RandomForestRegressor
    from sklearn.preprocessing import OneHotEncoder
    from sklearn.compose import ColumnTransformer
    from sklearn.pipeline import Pipeline
    
    # Identify categorical columns
    categorical_features = X_train.select_dtypes(include=['object']).columns
    
    # Create a column transformer to apply one-hot encoding
    preprocessor = ColumnTransformer(
        transformers=[
            ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)
        ],
        remainder='passthrough' # Keep other columns (numerical)
    )
    
    # Create a pipeline with the preprocessor and the model
    model = Pipeline(steps=[('preprocessor', preprocessor),
                          ('regressor', RandomForestRegressor(n_estimators=100, random_state=42))])
    
    # Convert the target variable to integers
    y_train = y_train.astype(float) # Convert to float for regression
    
    model.fit(X_train, y_train)
    return model

model = treinar_modelo_uci(X_train, y_train)

"""
## Avalia√ß√£o do modelo
"""

from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.metrics import confusion_matrix, classification_report

import numpy as np

# Make predictions on the test data
try:
    predictions = model.predict(X_test)
    
    # Debug: Verificar tipos e formas
    st.markdown("### Debug do Modelo")
    st.write(f"**y_test type:** {type(y_test)}, **shape:** {y_test.shape if hasattr(y_test, 'shape') else 'N/A'}")
    st.write(f"**predictions type:** {type(predictions)}, **shape:** {predictions.shape if hasattr(predictions, 'shape') else 'N/A'}")
    
    # Verificar valores NaN e infinitos
    y_test_nan = pd.isna(y_test).sum() if hasattr(y_test, 'sum') else 0
    predictions_nan = pd.isna(predictions).sum() if hasattr(predictions, 'sum') else 0
    st.write(f"**y_test NaN count:** {y_test_nan}")
    st.write(f"**predictions NaN count:** {predictions_nan}")
    
    # Evaluate the model using regression metrics with data cleaning
    try:
        # Garantir que os dados s√£o arrays numpy
        y_test_clean = np.asarray(y_test, dtype=float)
        predictions_clean = np.asarray(predictions, dtype=float)
        
        # Remover valores NaN e infinitos
        mask = np.isfinite(y_test_clean) & np.isfinite(predictions_clean)
        y_test_clean = y_test_clean[mask]
        predictions_clean = predictions_clean[mask]
        
        st.write(f"**Dados limpos - y_test shape:** {y_test_clean.shape}, **predictions shape:** {predictions_clean.shape}")
        
        # Calcular m√©tricas
        mae = mean_absolute_error(y_test_clean, predictions_clean)
        rmse = np.sqrt(mean_squared_error(y_test_clean, predictions_clean))
        r2 = r2_score(y_test_clean, predictions_clean)
        
        st.markdown("### M√©tricas do Modelo")
        st.markdown(f"**Mean Absolute Error (MAE):** {mae:.2f}")
        st.markdown(f"**Root Mean Squared Error (RMSE):** {rmse:.2f}")
        st.markdown(f"**R-squared (R2):** {r2:.2f}")
        
    except Exception as e:
        st.error(f"Erro ao calcular m√©tricas: {e}")
        st.markdown("**Dados de debug:**")
        st.write(f"y_test sample: {y_test.head() if hasattr(y_test, 'head') else y_test}")
        st.write(f"predictions sample: {predictions[:5] if hasattr(predictions, '__len__') else predictions}")
        
except Exception as e:
    st.error(f"Erro na previs√£o do modelo: {e}")
    import traceback
    st.code(traceback.format_exc())

from sklearn.inspection import permutation_importance

result = permutation_importance(model, X_test, y_test, n_repeats=10, random_state=42, n_jobs=2)
sorted_idx = result.importances_mean.argsort()

fig, ax = plt.subplots(figsize=(12, 10))
ax.boxplot(result.importances[sorted_idx].T,
           vert=False, labels=X_test.columns[sorted_idx])
ax.set_title("Import√¢ncia das classes")
fig.tight_layout()
st.pyplot(fig)

"""
Foi poss√≠vel observar que a notal final (G3) √© fortemente influenciada, em termos absolutos, pelas notas anteriores e a quantidade de faltas.
"""
'''
## Conclus√£o

A an√°lise dos dados mostra que a maioria dos estudantes tem entre 15 e 19 anos, com uma m√©dia de horas semanais livres um pouco acima de 3h, e a maior parte das faltas concentra-se pr√≥ximo a zero. As notas finais est√£o concentradas acima da mediana com dispers√£o aceit√°vel, tendo coeficiente de varia√ß√£o em torno de 27%. O gr√°fico indica uma ligeira tend√™ncia de queda na nota final conforme o n√∫mero de faltas aumenta, especialmente a partir da faixa de 11-15 faltas, onde estudantes com menos de 10 faltas alcan√ßam notas m√°ximas e concentram-se entre 10 e 14 pontos  . A correla√ß√£o entre horas de estudo e pontua√ß√£o final revela que 75% dos alunos que dedicam menos de 2 horas por semana obt√™m pontua√ß√£o inferior a 13, enquanto aqueles que estudam de 5 a 10h t√™m concentra√ß√£o de notas mais altas  . Uma an√°lise das notas finais por g√™nero mostra que, apesar da distribui√ß√£o e variabilidade serem parecidas, a mediana das notas femininas √© um pouco mais alta que a dos homens  .
'''

# Salvando os resultados no formato pickle
with open('uci.pkl', 'wb') as f:
    pickle.dump(model, f)
    f.close()

# Se√ß√£o de an√°lise interativa (PyGWalker movido para o dashboard principal)
st.markdown("---")
st.markdown("### üîç An√°lise Interativa")
st.info("üí° Para an√°lise interativa dos dados, utilize a aba 'Feature Importance' no painel anal√≠tico principal, onde voc√™ pode ativar o PyGWalker de forma opcional.")